#!/bin/bash

#******************************************************************************
#
# DESCRIPTION:       This bash script is used to external from netCDF files
#                    the vertical measure in a single point in Adriatic Sea
#                    put the data in an external .txt file that will be 
#                    processed by R to calculate some statistical important tests
#
# EXTERNAL CALLS:   none.
#
# EXTERNAL FILES:   - input NetCDF data file
#                     Containing whatever
#                   - DATA ASCII file provided by Massimo Celio
#
# DEVELOPER:         Alex Pividori (alex.pividori@arpa.fvg.it)
#                    ARPA FVG - S.O.C. Stato dell'Ambiente - CRMA
#                   "AdriaClim" Interreg IT-HR project
#
# SOFTWARE VERSION: Bash
#                   CDO version 1.9.8
#
# CREATION DATE:    05/04/2023
#
# MODIFICATIONS:    05/04/2023 --> Transformation into a job
#
# VERSION:          0.1.
#
#******************************************************************************

#PBS -N T_sel_drops_arpae
#PBS -o stdout_T
#PBS -e stderr_T
#PBS -P CASCADE
#PBS -W umask=0002
#PBS -q arpa
#PBS -l nodes=1:ppn=1
#PBS -l walltime=%%wall_time%%
##PBS -m abe
##PBS -M alex.pividori@arpa.fvg.it
#PBS -W block=true

cd            %%tmp_dir_root%%
module load   %%cdo_module%%

point_name="%%point_name%%"
find_arc_dir="%%find_arc_dir%%"
output_d="%%drops_files_dir%%"
netCDF_file="%%netCDF_file%%"
last_netCDF_dt_TEMP="%%last_netCDF_dt_TEMP%%"

i=1
n_elem=0
depth_old="0"
depth_new="0"
n_lines=$( wc -l < ${output_d}/list_lines.txt )

#===============================================================================================

if [[ -f "$output_d/list_files_TEMP.txt"  ]]; then rm "$output_d/list_files_TEMP.txt"; fi

#========================= A first drop measure will be extracted ==============================

# i starts from 1 (the first line) of "$output_d/list_lines.txt" file
while [ $i -le $(( n_lines + 1 )) ] ; do           # the last cycle is necessary to launch the cdo interpolation for the last drop present 
                                                   # inside list_lines.txt file

	if (( $( echo "$depth_old <= $depth_new" | bc ) )) && [[ $i -le $n_lines ]]; then

   	    ser_code=$(  sed -n "${i}p"          $output_d/list_lines.txt | awk -F ";"   '{ print $1 }'  )

       	    depth_old=$( sed -n "${i}p"          $output_d/list_lines.txt | awk -F ";"   '{ print $6 }'  )
    	    depth_new=$( sed -n "$(( i + 1 ))p"  $output_d/list_lines.txt | awk -F ";"   '{ print $6 }'  )

      	    lat_m=$(     sed -n "${i}p"          $output_d/list_lines.txt | awk -F ";"   '{ print $5 }'  )
      	    lon_m=$(     sed -n "${i}p"          $output_d/list_lines.txt | awk -F ";"   '{ print $4 }'  )

     	    date_m=$(    sed -n "${i}p"          $output_d/list_lines.txt | awk -F ";"   '{ print $2 }'  )
    	    time_m=$(    sed -n "${i}p"          $output_d/list_lines.txt | awk -F ";"   '{ print $3 }'  )

    	    depth=$depth_old
            temp=$(      sed -n "${i}p"          $output_d/list_lines.txt | awk -F ";"   '{ print $7 }' )

            if (( $( echo "$depth_old <= $depth_new" | bc ) )) || [[ $i -eq $n_lines ]]; then i=$(( i + 1 )); fi

 	     depth_val[${n_elem}]=$depth
 	     n_elem=$(( n_elem + 1 ))
             echo "${ser_code};${lat_m};${lon_m};${date_m};${time_m};${depth};${temp}" >> "${output_d}/${ser_code}_${date_m}_m_TEMP.txt"

	else   # the measured drop is finished. Now the code pass to the model data-part

            echo -e "\n\t cdo analysis for the single drop of $ser_code station in $date_time is starting"

            n_elem=0
            i=$(( i + 1 ))   # i index must be incremented in the if and in the else statement

            #=====================================================================================
            #           Creation of comparison file from COPERNICUS MARINE netCDF files
            #=====================================================================================


            echo -e "\n\t The netCDF TEMP file  used is \"$netCDF_file\" \n"

            case $point_name in
            1014)
                index_lat=18
                index_lon=15
            ;;
            2014)
                index_lat=20
                index_lon=21
            ;;
            1019)
                index_lat=8
                index_lon=30
            ;;
            604)
                index_lat=38
                index_lon=7
            ;;
            619)
                index_lat=6
                index_lon=29
            ;;
            614)
                index_lat=17
                index_lon=13
            ;;
            2004)
                index_lat=38
                index_lon=15
            ;;
            1004)
                index_lat=38
                index_lon=9
            ;;
            *)
                echo "ERROR: The point name ${point_name} is not available."
                exit
            ;;
            esac


            echo "cdo is extractind sal data for ${point_name} is index_lat=$index_lat and index_lon=$index_lon and datetime: ${date_m},${time_m}"

            if [[ "${date_m}_${time_m}" < "${last_netCDF_dt_TEMP}" ]]; then

                # interpolate levels withoux extrapolation
                cdo    -outputf,%2.4g,1    -intlevel$( printf ',%s'  "${depth_val[@]}" )    -inttime,${date_m},${time_m}    -selname,votemper  \
                       -selindexbox,$index_lon,$index_lon,$index_lat,$index_lat  $find_arc_dir/$netCDF_file  >  "${output_d}/${ser_code}_${date_m}_f_TEMP.txt"            

                #===============================================================================
                #                     PASTE the TWO files: measure and forecasts
                #===============================================================================

                if [[ ! -s "${output_d}/${ser_code}_${date_m}_f_TEMP.txt" ]]; then 
                    echo "\"${output_d}/${ser_code}_${date_m}_f_TEMP.txt\" file is empry or it doesn't exists. "
                    rm "${output_d}/${ser_code}_${date_m}_f_TEMP.txt"
                    rm "${output_d}/${ser_code}_${date_m}_m_TEMP.txt"
                    unset depth_val
                    depth_new="0"; depth_old="0"
                    continue
                fi

                paste -d ";" "$output_d/${ser_code}_${date_m}_m_TEMP.txt"     "$output_d/${ser_code}_${date_m}_f_TEMP.txt" | grep -v ";;" | grep -v "1e+20" | grep -v "00$" \
                           > "$output_d/${ser_code}_${date_m}_${time_m//:/-}_TEMP.txt" || echo "pasting process for $output_d/${ser_code}_${date_m}_m_TEMP.txt not valid"

                if [[ -f $output_d/${ser_code}_${date_m}_m_TEMP.txt  ]]; then rm "$output_d/${ser_code}_${date_m}_m_TEMP.txt"; fi 
                if [[ -f $output_d/${ser_code}_${date_m}_f_TEMP.txt  ]]; then rm "$output_d/${ser_code}_${date_m}_f_TEMP.txt"; fi

:<<blocco
                val=$( awk "BEGIN { print $( sed -n "1p"   "$output_d/${ser_code}_${date_m}_${time_m//:/-}_TEMP.txt"  | awk -F ";"   '{ print $8 }' ) }" )

                if [[ ${val%%.*} -lt 1000000 && "${val%%.*}" != "" ]]; then                                   # the missing value is 1e+20 but also 1000000 could be fine
                    echo "${ser_code}_${date_m}_${time_m//:/-}_TEMP.txt" >> $output_d/list_files_TEMP.txt   # file creation with the names of the files
                    echo -e "\n\t File \"${ser_code}_${date_m}_${time_m//:/-}_TEMP.txt\" is now available for forward analysis"
                else
                    rm    "${output_d}/${ser_code}_${date_m}_${time_m//:/-}_TEMP.txt"
                    echo -e "\t File \"${ser_code}_${date_m}_${time_m//:/-}_TEMP.txt\" has been removed due to external to model domain."
                fi
blocco
#************** reinitialize variables ************************
            else
                 rm "$output_d/${ser_code}_${date_m}_m_TEMP.txt"
            fi
                unset depth_val
                depth_new="0"
                depth_old="0"

        fi

done

echo -e "\n"
